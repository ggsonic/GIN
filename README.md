# GIN
Official repository for the work: "Preliminary concept of General intelligent network (GIN) for brain-like intelligence"[[pdf](https://vixra.org/pdf/2201.0188v1.pdf)]

# Some Explanation

* HPP  Why we name it HPP? Because HPP is different from embeddings. As for HPP, The basic element is state or node with acting edges or branches,with each branch with  a particular context. Deep Learning Models can learn individual embeddings, but HPP is  learned from contextual related environment.

* NKC  The process of Neural Knowledge Compression do similar thing like encoding HPPs. With input horizontal sequence-to-sequence HPPs, NKC got output one HPP with branch-to-branch forward graph, a.k.a a new HPP graph. NKC keep running when people are sleeping, with brain's memory space freed up and got deeper knowledge and wisdom.

* GIN  GIN is based on HPP dynamics and Autonomous NKC, it is totally different from modern Deep Learning models.

* CFR  In our paper, Deep Learning optimization process is essentially a variant of counterfactual regret minimization (CFR). This concept was first proposed so far as we know. As presented in our paper, in inner information sets, each inner state node does not know which of the node states it is in. Self-Attention or MLP are alignment of different strategies.
